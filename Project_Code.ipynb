{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTeLwWc8MMBO"
   },
   "source": [
    "# Text Prediction and Generation using LSTM Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwK0g5gV5hTi"
   },
   "source": [
    "_______________\n",
    "## Google drive code only\n",
    "Only run the following sections in a colaboratory shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30489,
     "status": "ok",
     "timestamp": 1551835746036,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "h7P6a2_l5hTj",
    "outputId": "abe81f01-fa9e-4694-f575-e042e4fd56a3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Code to read google drive files into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30454,
     "status": "ok",
     "timestamp": 1551835746039,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "ujVuCb3iRW8G",
    "outputId": "6ebda17c-e353-49d8-9942-0619a3e141ed"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def importFile(fileName: str, fileID: str):\n",
    "  '''Imports a file into the Colaboratory workspace. The fileID can be \n",
    "     found in the file's Share Link'''\n",
    "  print(\"Grabbing file \" + str(fileName) + \" with id = \" + str(fileID)) # Verify that you have everything after '='\n",
    "  downloaded = drive.CreateFile({'id':fileID}) \n",
    "  downloaded.GetContentFile(fileName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93955,
     "status": "ok",
     "timestamp": 1551835809588,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "r7xpitMqO8bN",
    "outputId": "98facc28-f472-4d9c-efa6-b343038a8d19"
   },
   "outputs": [],
   "source": [
    "# Import all the datasets we are going to use for our project\n",
    "importFile('TheLordOfTheRings_Book1.txt', '1crAeSigOaQcT62W7EjcwrKcIVBx5ayeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93955,
     "status": "ok",
     "timestamp": 1551835809588,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "r7xpitMqO8bN",
    "outputId": "98facc28-f472-4d9c-efa6-b343038a8d19"
   },
   "outputs": [],
   "source": [
    "importFile('GoogleNews-vectors-negative300.bin', '1zzUeVFsRYw3lWe6kjk1nccywCkMDp-AY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0owQf_T5hTr"
   },
   "source": [
    "## End of Google drive code\n",
    "_________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ODs77INUaJl"
   },
   "source": [
    "## Setup Word Embeddings\n",
    "\n",
    "- Load top 1 million (out of 3 million) word embeddings from the binary file.\n",
    "- The vectors are 300 dimensions large and are created using the word2vec algorithm.\n",
    "- The model was trained on the GoogleNews corpus and the vector is taken from a latent layer, representing a compressed representation of a word with its surrounding context.  \n",
    "    - The GoogleNews corpus is a similar size to the English version of Wikipedia.\n",
    "- We cannot load all 3,000,000 vectors or else we will run out of RAM.\n",
    "    - Missing words will be added programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ODs77INUaJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "# This line imports 100,000 vectors\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', limit=100000, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_WqVQBraIN7"
   },
   "source": [
    "### Word Embedding Examples\n",
    "\n",
    "When we import the binary file using the gensim library, we can easily explore interesting properties of word embeddings. Much like a latent vector produced using an autoencoder, each embedding holds meaningful information about each word and the context in which it is used. The following examples explore the latent space in which these vectors reside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 97713,
     "status": "ok",
     "timestamp": 1551835813375,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "pC_Da54bPmGt",
    "outputId": "7f5501f4-7e80-4d3e-8294-b5620bad5300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('teenage_girl', 0.7674504518508911), ('teenager', 0.7674364447593689), ('toddler', 0.701943576335907)]\n",
      "[('striped_bass', 0.47242963314056396), ('halibut', 0.43524497747421265), ('rockfish', 0.4258560836315155)]\n",
      "[('woman', 0.9972377419471741)]\n"
     ]
    }
   ],
   "source": [
    "# Vector addition/subtraction examples:\n",
    "# What are the top three vectors similar to boy and girl?\n",
    "print(embeddings.most_similar(positive=[\"boy\", \"girl\"], topn=3))\n",
    "# What is a fish without water?\n",
    "print(embeddings.most_similar(positive=[\"fish\"], negative=[\"water\"], topn=3)) \n",
    "\n",
    "# Can also obtain nearby vectors. Here of an example where we slightly modify \n",
    "# the \"woman\" vectors and test if we can get back the same bector using the most_similar function\n",
    "v = np.copy(embeddings[\"woman\"])\n",
    "v[0] += 0.2\n",
    "print(embeddings.most_similar(positive=[v], topn=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bF-OhBj7aFDY"
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1e9PxMNKjTXDx7KZDxHpC4ENmz0sXHl_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: Word embeddings organize terms based on the context in which they are used. All three example images demonstrate possible transformation functions that convey structure in the latent space. In the \"Male-Female\" image, there exists a function that relates male-oriented words to their corresponding female-oriented words. In the \"Verb Tense\" image, there exists a function that maps a present-tense word to its past-tense conjugation. In the \"Country-Capital\" image, there exists a function that relates a country to its corresponding capital city.\n",
    "\n",
    "_________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iuvUj83Fb1ug"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Split training data into individual tokens, ie: \"Here is a sentence\" --> \\[\"Here\" \"is\" \"a\" \"sentence\"\\]\n",
    "2. Use nltk to split training data into ngram phrases to feed into our LSTM network\n",
    "    - The model's architecture will automatically adjust based on ngram size\n",
    "3. Shuffle the data\n",
    "4. Split the data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 100774,
     "status": "ok",
     "timestamp": 1551835816464,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "mz9lUGnqWNGd",
    "outputId": "3d2647f0-20cf-417d-ac5c-105cf99e5803"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Eric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def tokenizeFile(fileName: str) -> list:\n",
    "    '''Will take in the name of a txt file located in the base directory \n",
    "    of the drive and return a list of tokens. Tokens are defined to be\n",
    "    any nonzero sequence of characters.'''\n",
    "    tokens = []\n",
    "    with open(fileName, 'r', encoding=\"ISO-8859-1\") as file:\n",
    "        tokens = word_tokenize(file.read())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 100774,
     "status": "ok",
     "timestamp": 1551835816464,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "mz9lUGnqWNGd",
    "outputId": "3d2647f0-20cf-417d-ac5c-105cf99e5803"
   },
   "outputs": [],
   "source": [
    "# Used to generate new embeddings with random weights\n",
    "seed = 0\n",
    "# Used to store only the word vectors we come across in a file\n",
    "my_embeddings = gensim.models.keyedvectors.WordEmbeddingsKeyedVectors(300)\n",
    "\n",
    "\n",
    "def addNewEmbedding(token: str):\n",
    "    '''Adds a new word embedding to our vector set with randomly initialized values.\n",
    "    Returns the newly created embedding.'''\n",
    "    global seed\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    weights = np.random.uniform(-1,1,300)\n",
    "    my_embeddings.add(token, weights)\n",
    "    return my_embeddings[token]\n",
    "\n",
    "\n",
    "def flipFirstChar(word: str) -> str:\n",
    "    '''Capitalizes/Un-capitalizes the first character of the word.\n",
    "    It is not garunteed that all terms in the WordNet corpus are lower\n",
    "    case or upper case. So if we can't find a term then it is a good \n",
    "    idea to fip the first character's case and try again. '''\n",
    "    if word[0].isupper():\n",
    "        return word[0].lower() + word[1:]\n",
    "    else:\n",
    "        return word[0].upper() + word[1:]\n",
    "\n",
    "\n",
    "def tokensToVectors(tokens: list) -> (list, list):\n",
    "    '''Convert a list of terms into a list of word embeddings. \n",
    "    If an embeddding exists for a term, we add it to our vector set.\n",
    "    If an embedding does not exist for a term, we create a new embedding and add it to our vector set.'''\n",
    "    vectors = []\n",
    "    unknownTokens = set()\n",
    "    for token in tokens:\n",
    "        # The vector exists in the GoogleNews vector set\n",
    "        if token in embeddings:\n",
    "            weights = embeddings[token]\n",
    "            vectors.append(weights)\n",
    "            my_embeddings.add(token, weights)\n",
    "        # The flipFirstChar'ed vector exists in the GoogleNews vector set\n",
    "        elif flipFirstChar(token) in embeddings:\n",
    "            weights = embeddings[flipFirstChar(token)]\n",
    "            vectors.append(weights)\n",
    "            my_embeddings.add(token, weights)\n",
    "        # The vector does not exist so make a new vector\n",
    "        else:\n",
    "            weights = addNewEmbedding(token)\n",
    "            vectors.append(weights)\n",
    "            unknownTokens.add(token)\n",
    "    return vectors, unknownTokens\n",
    "\n",
    "\n",
    "def phrasesToVectors(ngramList: list, summary=True) -> (list, list):\n",
    "    '''Calls wordsToVectors() on a list of lists. This function will be called\n",
    "       after data is split into ngrams. Each phrase in the code below operations\n",
    "       on a single ngram.'''\n",
    "    ngramVectorList = []\n",
    "    allUnknownTokens = set()\n",
    "    for tokens in ngramList:\n",
    "        vectors, unknownTokens = tokensToVectors(tokens)\n",
    "        ngramVectorList.append(vectors)\n",
    "        allUnknownTokens = allUnknownTokens.union(unknownTokens)  \n",
    "    if summary:\n",
    "        print(\"Number of training ngrams: \" + str(len(ngramVectorList)))\n",
    "        print(\"Number of unknown vector terms created: \" + str(len(allUnknownTokens)))\n",
    "    print(\"Shape of training set: \" + str(np.shape(ngramVectorList)))\n",
    "    return np.array(ngramVectorList, dtype=np.ndarray), allUnknownTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120045,
     "status": "ok",
     "timestamp": 1551835835756,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "uU-H6dNE5hT5",
    "outputId": "c658075b-f9ee-4869-e94c-47e7a3ab7e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4435 non-unique words from the text\n",
      "Number of training ngrams: 4415\n",
      "Number of unknown vector terms created: 149\n",
      "Shape of training set: (4415, 21, 300)\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk import ngrams\n",
    "\n",
    "# Cut number of words so we can fit everything in memory\n",
    "words_all = tokenizeFile(\"TheLordOfTheRings_Book1.txt\")\n",
    "words = words_all[:len(words_all)//50]\n",
    "print(\"Using \" + str(len(words)) + \" non-unique words from the text\")\n",
    "# Change this parameter to decrease or increase the size of the training samples\n",
    "N = 20\n",
    "ngrams_words = ngrams(words, N + 1)\n",
    "# ngram_vectors_original, _ = phrasesToVectors(ngrams_words)\n",
    "ngram_vectors, _ = phrasesToVectors(ngrams_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120030,
     "status": "ok",
     "timestamp": 1551835835763,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "qEfgIpp15hT9",
    "outputId": "f7ff6c92-2cc2-42d3-97ee-6f07d59551eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Shape: (4415, 21, 300)\n",
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make a copy of the original ngrams just in case we want to run our model with different parameters\n",
    "# ngram_vectors = ngram_vectors_original\n",
    "# Shuffling the data to increase validation accuracy\n",
    "np.random.shuffle(ngram_vectors)\n",
    "print(\"Samples Shape: \" + str(ngram_vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBUN5Hjf5hUA"
   },
   "source": [
    "### Training/Validation Split\n",
    "First we will set aside 10% of our data for validation. \n",
    "\n",
    "Each phrase (element) in ngram_vectors will be split into two parts. All the terms preceeding the last term will be used to predict the last term. So, if we have an array of phrases of size six, then these phrases will be split into two arrays of equal size. For example: \n",
    "\n",
    "phrase: \\[This tale grew in the telling\\]\n",
    " - input data = \\[This tale grew in the\\]\n",
    " - expected output = \\[tale grew in the telling\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120016,
     "status": "ok",
     "timestamp": 1551835835768,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "6l2HRpsmaK84",
    "outputId": "c0b380ba-6ab6-4836-e401-7b5f6cc38358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Input: (3973, 20, 300), Training Predict: (3973, 20, 300)\n",
      "Validation Input: (442, 20, 300), Validation Predict: (442, 20, 300)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Split data into training and validation\n",
    "split = math.floor(np.size(ngram_vectors, axis=0) * 0.9)\n",
    "training = ngram_vectors[:split,:,:]\n",
    "validation = ngram_vectors[split:,:,:]\n",
    "\n",
    "# Split the training and validation data as discussed above ^\n",
    "train_input = training[:,:-1,:]\n",
    "# train_predict = np.expand_dims(training[:,-1,:], axis=1)\n",
    "train_predict = training[:,1:,:]\n",
    "\n",
    "\n",
    "validation_input = validation[:,:-1,:]\n",
    "# validation_predict = np.expand_dims(validation[:,-1,:], axis=1)\n",
    "validation_predict = validation[:,1:,:]\n",
    "\n",
    "print(\"Training Input: \" + str(train_input.shape) + \", Training Predict: \" + str(train_predict.shape))\n",
    "print(\"Validation Input: \" + str(validation_input.shape) + \", Validation Predict: \" + str(validation_predict.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOYI6ZRM5hUE"
   },
   "source": [
    "## Architecture Explaination\n",
    "\n",
    "- The input shape is 300 because we take in each dimension of the word embedding as input.\n",
    "- The default Tanh activation function is used on LSTM cells.\n",
    "- No dropout layers are used because they decrease training accuracy with negligible improvements to validation accuracy.\n",
    "- Tanh activation function is used on the final dense layer to restrict the output of the vector from -1 to 1 because word embeddings are normalized betweeen -1 and 1.\n",
    "- A third LSTM layer increases training and validation accuracy\n",
    "- Loss is cosine similarity because word2vec also uses cosine similarity to measure the distance between word vectors.\n",
    "\n",
    "This table represents our adjustments to the model with its corresponding testing and validation scores. All results use 100 epochs, a batch size of 32, and a cosine proximity loss function.\n",
    "\n",
    "| Description | Training Accuracy | Validation Accuracy | |\n",
    "|------|------|------|-|\n",
    "| 2 LSTM with sigmoid<br>1 Dense with no activation | 0.4603 | 0.3670 ||\n",
    "| 2 LSTM with tanh<br>2 Dropout<br>1 Dense with no activation | 0.4067 | 0.3761 ||\n",
    "| 2 LSTM with tanh<br>2 Dropout<br>1 Dense with tanh | 0.4219 | 0.3946 ||\n",
    "| 2 LSTM with tanh<br>1 Dense with no activation | 0.4978 | 0.3707 ||\n",
    "| 2 LSTM with tanh<br>1 Dense with tanh | 0.5012 | 0.3887 ||\n",
    "| 3 LSTM with tanh<br>1 Dense with tanh | 0.5548 | 0.4068 |Best Model|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121155,
     "status": "ok",
     "timestamp": 1551835836935,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "CymWYziXllRA",
    "outputId": "22e50a6c-fb33-4373-9d7b-c805e272890b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (20, 300)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20, 300)           721200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 300)           721200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20, 300)           721200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20, 300)           90300     \n",
      "=================================================================\n",
      "Total params: 2,253,900\n",
      "Trainable params: 2,253,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "input_shape=(N, 300)\n",
    "print(\"Input Shape: \" + str(input_shape))\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(LSTM(300, input_shape=input_shape, return_sequences=True, activation='tanh'))\n",
    "model.add(LSTM(300, return_sequences=True, activation='tanh'))\n",
    "model.add(LSTM(300, return_sequences=True, activation='tanh'))\n",
    "model.add(Dense(300, activation='tanh'))\n",
    "\n",
    "model.compile(loss='cosine_proximity', optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7075
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 350005,
     "status": "ok",
     "timestamp": 1551836065824,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "UaStJMjKWf7Y",
    "outputId": "9ae8ee3c-0f48-4cbe-eaa8-0eb90a562a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3973 samples, validate on 442 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: -3.5149e-01 - acc: 0.0447 - val_loss: -3.7576e-01 - val_acc: 0.0508\n",
      "Epoch 2/100\n",
      " - 12s - loss: -4.1037e-01 - acc: 0.0593 - val_loss: -4.4985e-01 - val_acc: 0.0770\n",
      "Epoch 3/100\n",
      " - 12s - loss: -4.9135e-01 - acc: 0.1061 - val_loss: -5.2551e-01 - val_acc: 0.1171\n",
      "Epoch 4/100\n",
      " - 12s - loss: -5.6391e-01 - acc: 0.1560 - val_loss: -5.9415e-01 - val_acc: 0.1771\n",
      "Epoch 5/100\n",
      " - 12s - loss: -6.3189e-01 - acc: 0.2027 - val_loss: -6.5706e-01 - val_acc: 0.2218\n",
      "Epoch 6/100\n",
      " - 12s - loss: -6.9450e-01 - acc: 0.2498 - val_loss: -7.1305e-01 - val_acc: 0.2612\n",
      "Epoch 7/100\n",
      " - 12s - loss: -7.4703e-01 - acc: 0.3017 - val_loss: -7.6147e-01 - val_acc: 0.3210\n",
      "Epoch 8/100\n",
      " - 12s - loss: -7.8897e-01 - acc: 0.3458 - val_loss: -7.9610e-01 - val_acc: 0.3484\n",
      "Epoch 9/100\n",
      " - 12s - loss: -8.1966e-01 - acc: 0.3859 - val_loss: -8.2111e-01 - val_acc: 0.3811\n",
      "Epoch 10/100\n",
      " - 12s - loss: -8.4196e-01 - acc: 0.4141 - val_loss: -8.4050e-01 - val_acc: 0.4210\n",
      "Epoch 11/100\n",
      " - 12s - loss: -8.5846e-01 - acc: 0.4431 - val_loss: -8.5452e-01 - val_acc: 0.4355\n",
      "Epoch 12/100\n",
      " - 12s - loss: -8.7188e-01 - acc: 0.4661 - val_loss: -8.6447e-01 - val_acc: 0.4716\n",
      "Epoch 13/100\n",
      " - 12s - loss: -8.8196e-01 - acc: 0.4834 - val_loss: -8.7220e-01 - val_acc: 0.4762\n",
      "Epoch 14/100\n",
      " - 12s - loss: -8.8971e-01 - acc: 0.5010 - val_loss: -8.8084e-01 - val_acc: 0.4956\n",
      "Epoch 15/100\n",
      " - 12s - loss: -8.9641e-01 - acc: 0.5157 - val_loss: -8.8671e-01 - val_acc: 0.5084\n",
      "Epoch 16/100\n",
      " - 11s - loss: -9.0222e-01 - acc: 0.5261 - val_loss: -8.9081e-01 - val_acc: 0.5102\n",
      "Epoch 17/100\n",
      " - 12s - loss: -9.0680e-01 - acc: 0.5374 - val_loss: -8.9481e-01 - val_acc: 0.5200\n",
      "Epoch 18/100\n",
      " - 12s - loss: -9.1067e-01 - acc: 0.5458 - val_loss: -8.9798e-01 - val_acc: 0.5090\n",
      "Epoch 19/100\n",
      " - 12s - loss: -9.1406e-01 - acc: 0.5516 - val_loss: -9.0123e-01 - val_acc: 0.5373\n",
      "Epoch 20/100\n",
      " - 12s - loss: -9.1727e-01 - acc: 0.5604 - val_loss: -9.0377e-01 - val_acc: 0.5463\n",
      "Epoch 21/100\n",
      " - 12s - loss: -9.2026e-01 - acc: 0.5697 - val_loss: -9.0675e-01 - val_acc: 0.5518\n",
      "Epoch 22/100\n",
      " - 11s - loss: -9.2307e-01 - acc: 0.5742 - val_loss: -9.0869e-01 - val_acc: 0.5563\n",
      "Epoch 23/100\n",
      " - 12s - loss: -9.2524e-01 - acc: 0.5777 - val_loss: -9.1030e-01 - val_acc: 0.5570\n",
      "Epoch 24/100\n",
      " - 12s - loss: -9.2701e-01 - acc: 0.5816 - val_loss: -9.1255e-01 - val_acc: 0.5748\n",
      "Epoch 25/100\n",
      " - 12s - loss: -9.2929e-01 - acc: 0.5898 - val_loss: -9.1384e-01 - val_acc: 0.5734\n",
      "Epoch 26/100\n",
      " - 12s - loss: -9.3084e-01 - acc: 0.5940 - val_loss: -9.1518e-01 - val_acc: 0.5874\n",
      "Epoch 27/100\n",
      " - 12s - loss: -9.3234e-01 - acc: 0.5962 - val_loss: -9.1665e-01 - val_acc: 0.5950\n",
      "Epoch 28/100\n",
      " - 12s - loss: -9.3358e-01 - acc: 0.6024 - val_loss: -9.1798e-01 - val_acc: 0.5851\n",
      "Epoch 29/100\n",
      " - 12s - loss: -9.3538e-01 - acc: 0.6075 - val_loss: -9.1881e-01 - val_acc: 0.5939\n",
      "Epoch 30/100\n",
      " - 12s - loss: -9.3630e-01 - acc: 0.6144 - val_loss: -9.1994e-01 - val_acc: 0.5837\n",
      "Epoch 31/100\n",
      " - 12s - loss: -9.3755e-01 - acc: 0.6141 - val_loss: -9.2142e-01 - val_acc: 0.6037\n",
      "Epoch 32/100\n",
      " - 12s - loss: -9.3867e-01 - acc: 0.6186 - val_loss: -9.2074e-01 - val_acc: 0.5957\n",
      "Epoch 33/100\n",
      " - 12s - loss: -9.3941e-01 - acc: 0.6228 - val_loss: -9.2297e-01 - val_acc: 0.5976\n",
      "Epoch 34/100\n",
      " - 12s - loss: -9.4041e-01 - acc: 0.6265 - val_loss: -9.2365e-01 - val_acc: 0.5974\n",
      "Epoch 35/100\n",
      " - 12s - loss: -9.4149e-01 - acc: 0.6258 - val_loss: -9.2412e-01 - val_acc: 0.6253\n",
      "Epoch 36/100\n",
      " - 12s - loss: -9.4240e-01 - acc: 0.6325 - val_loss: -9.2513e-01 - val_acc: 0.6181\n",
      "Epoch 37/100\n",
      " - 12s - loss: -9.4300e-01 - acc: 0.6352 - val_loss: -9.2614e-01 - val_acc: 0.6174\n",
      "Epoch 38/100\n",
      " - 12s - loss: -9.4402e-01 - acc: 0.6396 - val_loss: -9.2619e-01 - val_acc: 0.6096\n",
      "Epoch 39/100\n",
      " - 12s - loss: -9.4466e-01 - acc: 0.6414 - val_loss: -9.2744e-01 - val_acc: 0.6212\n",
      "Epoch 40/100\n",
      " - 12s - loss: -9.4546e-01 - acc: 0.6423 - val_loss: -9.2733e-01 - val_acc: 0.6266\n",
      "Epoch 41/100\n",
      " - 12s - loss: -9.4610e-01 - acc: 0.6473 - val_loss: -9.2778e-01 - val_acc: 0.6215\n",
      "Epoch 42/100\n",
      " - 12s - loss: -9.4671e-01 - acc: 0.6518 - val_loss: -9.2864e-01 - val_acc: 0.6305\n",
      "Epoch 43/100\n",
      " - 12s - loss: -9.4718e-01 - acc: 0.6493 - val_loss: -9.2907e-01 - val_acc: 0.6264\n",
      "Epoch 44/100\n",
      " - 12s - loss: -9.4769e-01 - acc: 0.6571 - val_loss: -9.2927e-01 - val_acc: 0.6268\n",
      "Epoch 45/100\n",
      " - 12s - loss: -9.4832e-01 - acc: 0.6551 - val_loss: -9.2973e-01 - val_acc: 0.6302\n",
      "Epoch 46/100\n",
      " - 12s - loss: -9.4882e-01 - acc: 0.6604 - val_loss: -9.3026e-01 - val_acc: 0.6446\n",
      "Epoch 47/100\n",
      " - 12s - loss: -9.4920e-01 - acc: 0.6621 - val_loss: -9.3117e-01 - val_acc: 0.6406\n",
      "Epoch 48/100\n",
      " - 12s - loss: -9.4975e-01 - acc: 0.6643 - val_loss: -9.3087e-01 - val_acc: 0.6325\n",
      "Epoch 49/100\n",
      " - 12s - loss: -9.4973e-01 - acc: 0.6657 - val_loss: -9.3171e-01 - val_acc: 0.6346\n",
      "Epoch 50/100\n",
      " - 12s - loss: -9.5088e-01 - acc: 0.6697 - val_loss: -9.3169e-01 - val_acc: 0.6473\n",
      "Epoch 51/100\n",
      " - 12s - loss: -9.5112e-01 - acc: 0.6731 - val_loss: -9.3207e-01 - val_acc: 0.6440\n",
      "Epoch 52/100\n",
      " - 12s - loss: -9.5164e-01 - acc: 0.6741 - val_loss: -9.3235e-01 - val_acc: 0.6489\n",
      "Epoch 53/100\n",
      " - 12s - loss: -9.5224e-01 - acc: 0.6754 - val_loss: -9.3271e-01 - val_acc: 0.6396\n",
      "Epoch 54/100\n",
      " - 12s - loss: -9.5195e-01 - acc: 0.6734 - val_loss: -9.3276e-01 - val_acc: 0.6372\n",
      "Epoch 55/100\n",
      " - 12s - loss: -9.5250e-01 - acc: 0.6733 - val_loss: -9.3336e-01 - val_acc: 0.6654\n",
      "Epoch 56/100\n",
      " - 12s - loss: -9.5325e-01 - acc: 0.6811 - val_loss: -9.3362e-01 - val_acc: 0.6541\n",
      "Epoch 57/100\n",
      " - 12s - loss: -9.5359e-01 - acc: 0.6801 - val_loss: -9.3406e-01 - val_acc: 0.6653\n",
      "Epoch 58/100\n",
      " - 12s - loss: -9.5390e-01 - acc: 0.6851 - val_loss: -9.3421e-01 - val_acc: 0.6561\n",
      "Epoch 59/100\n",
      " - 12s - loss: -9.5406e-01 - acc: 0.6833 - val_loss: -9.3422e-01 - val_acc: 0.6586\n",
      "Epoch 60/100\n",
      " - 12s - loss: -9.5427e-01 - acc: 0.6863 - val_loss: -9.3451e-01 - val_acc: 0.6597\n",
      "Epoch 61/100\n",
      " - 12s - loss: -9.5471e-01 - acc: 0.6877 - val_loss: -9.3494e-01 - val_acc: 0.6698\n",
      "Epoch 62/100\n",
      " - 12s - loss: -9.5502e-01 - acc: 0.6872 - val_loss: -9.3497e-01 - val_acc: 0.6696\n",
      "Epoch 63/100\n",
      " - 12s - loss: -9.5530e-01 - acc: 0.6908 - val_loss: -9.3551e-01 - val_acc: 0.6683\n",
      "Epoch 64/100\n",
      " - 12s - loss: -9.5561e-01 - acc: 0.6937 - val_loss: -9.3542e-01 - val_acc: 0.6758\n",
      "Epoch 65/100\n",
      " - 12s - loss: -9.5583e-01 - acc: 0.6935 - val_loss: -9.3562e-01 - val_acc: 0.6679\n",
      "Epoch 66/100\n",
      " - 12s - loss: -9.5600e-01 - acc: 0.6956 - val_loss: -9.3589e-01 - val_acc: 0.6544\n",
      "Epoch 67/100\n",
      " - 12s - loss: -9.5616e-01 - acc: 0.6931 - val_loss: -9.3599e-01 - val_acc: 0.6795\n",
      "Epoch 68/100\n",
      " - 12s - loss: -9.5686e-01 - acc: 0.6998 - val_loss: -9.3592e-01 - val_acc: 0.6834\n",
      "Epoch 69/100\n",
      " - 12s - loss: -9.5624e-01 - acc: 0.7007 - val_loss: -9.3611e-01 - val_acc: 0.6690\n",
      "Epoch 70/100\n",
      " - 12s - loss: -9.5685e-01 - acc: 0.6993 - val_loss: -9.3649e-01 - val_acc: 0.6895\n",
      "Epoch 71/100\n",
      " - 12s - loss: -9.5722e-01 - acc: 0.7011 - val_loss: -9.3654e-01 - val_acc: 0.6855\n",
      "Epoch 72/100\n",
      " - 12s - loss: -9.5738e-01 - acc: 0.7039 - val_loss: -9.3700e-01 - val_acc: 0.6799\n",
      "Epoch 73/100\n",
      " - 12s - loss: -9.5770e-01 - acc: 0.7040 - val_loss: -9.3724e-01 - val_acc: 0.6882\n",
      "Epoch 74/100\n",
      " - 12s - loss: -9.5794e-01 - acc: 0.7091 - val_loss: -9.3760e-01 - val_acc: 0.6913\n",
      "Epoch 75/100\n",
      " - 12s - loss: -9.5803e-01 - acc: 0.7106 - val_loss: -9.3757e-01 - val_acc: 0.6704\n",
      "Epoch 76/100\n",
      " - 12s - loss: -9.5829e-01 - acc: 0.7044 - val_loss: -9.3726e-01 - val_acc: 0.6827\n",
      "Epoch 77/100\n",
      " - 12s - loss: -9.5850e-01 - acc: 0.7071 - val_loss: -9.3758e-01 - val_acc: 0.6912\n",
      "Epoch 78/100\n",
      " - 12s - loss: -9.5875e-01 - acc: 0.7118 - val_loss: -9.3763e-01 - val_acc: 0.6822\n",
      "Epoch 79/100\n",
      " - 12s - loss: -9.5878e-01 - acc: 0.7114 - val_loss: -9.3767e-01 - val_acc: 0.6745\n",
      "Epoch 80/100\n",
      " - 12s - loss: -9.5902e-01 - acc: 0.7149 - val_loss: -9.3740e-01 - val_acc: 0.6859\n",
      "Epoch 81/100\n",
      " - 12s - loss: -9.5907e-01 - acc: 0.7080 - val_loss: -9.3824e-01 - val_acc: 0.6826\n",
      "Epoch 82/100\n",
      " - 12s - loss: -9.5939e-01 - acc: 0.7165 - val_loss: -9.3818e-01 - val_acc: 0.6871\n",
      "Epoch 83/100\n",
      " - 12s - loss: -9.5946e-01 - acc: 0.7149 - val_loss: -9.3808e-01 - val_acc: 0.6835\n",
      "Epoch 84/100\n",
      " - 12s - loss: -9.5959e-01 - acc: 0.7145 - val_loss: -9.3855e-01 - val_acc: 0.6933\n",
      "Epoch 85/100\n",
      " - 12s - loss: -9.5997e-01 - acc: 0.7177 - val_loss: -9.3863e-01 - val_acc: 0.6965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      " - 12s - loss: -9.5981e-01 - acc: 0.7194 - val_loss: -9.3841e-01 - val_acc: 0.6844\n",
      "Epoch 87/100\n",
      " - 12s - loss: -9.6000e-01 - acc: 0.7209 - val_loss: -9.3904e-01 - val_acc: 0.6920\n",
      "Epoch 88/100\n",
      " - 11s - loss: -9.6035e-01 - acc: 0.7241 - val_loss: -9.3889e-01 - val_acc: 0.6852\n",
      "Epoch 89/100\n",
      " - 12s - loss: -9.6033e-01 - acc: 0.7219 - val_loss: -9.3881e-01 - val_acc: 0.6887\n",
      "Epoch 90/100\n",
      " - 12s - loss: -9.6030e-01 - acc: 0.7236 - val_loss: -9.3937e-01 - val_acc: 0.7017\n",
      "Epoch 91/100\n",
      " - 12s - loss: -9.6081e-01 - acc: 0.7276 - val_loss: -9.3906e-01 - val_acc: 0.6936\n",
      "Epoch 92/100\n",
      " - 12s - loss: -9.6077e-01 - acc: 0.7247 - val_loss: -9.3916e-01 - val_acc: 0.7037\n",
      "Epoch 93/100\n",
      " - 12s - loss: -9.6108e-01 - acc: 0.7281 - val_loss: -9.3938e-01 - val_acc: 0.7051\n",
      "Epoch 94/100\n",
      " - 12s - loss: -9.6121e-01 - acc: 0.7270 - val_loss: -9.3927e-01 - val_acc: 0.7051\n",
      "Epoch 95/100\n",
      " - 12s - loss: -9.6134e-01 - acc: 0.7281 - val_loss: -9.3953e-01 - val_acc: 0.7009\n",
      "Epoch 96/100\n",
      " - 12s - loss: -9.6140e-01 - acc: 0.7292 - val_loss: -9.3972e-01 - val_acc: 0.7068\n",
      "Epoch 97/100\n",
      " - 12s - loss: -9.6154e-01 - acc: 0.7322 - val_loss: -9.3967e-01 - val_acc: 0.7143\n",
      "Epoch 98/100\n",
      " - 12s - loss: -9.6157e-01 - acc: 0.7330 - val_loss: -9.3980e-01 - val_acc: 0.6995\n",
      "Epoch 99/100\n",
      " - 12s - loss: -9.6177e-01 - acc: 0.7322 - val_loss: -9.3984e-01 - val_acc: 0.7143\n",
      "Epoch 100/100\n",
      " - 12s - loss: -9.6182e-01 - acc: 0.7357 - val_loss: -9.3980e-01 - val_acc: 0.6977\n",
      "Wall time: 19min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(train_input, train_predict, epochs=100, batch_size=32, verbose=2, validation_data=(validation_input, validation_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 350738,
     "status": "ok",
     "timestamp": 1551836066606,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "_Z6NaUjF5hUT",
    "outputId": "db8a1159-369a-4ebb-ba7b-c99cd9cd31f0"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_accuracy(history):\n",
    "  plt.plot(history.history['acc'],label='train')\n",
    "  if 'val_acc' in history.history:\n",
    "    plt.plot(history.history['val_acc'],label='val')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.title('Accuracy during Training')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 350738,
     "status": "ok",
     "timestamp": 1551836066606,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "_Z6NaUjF5hUT",
    "outputId": "db8a1159-369a-4ebb-ba7b-c99cd9cd31f0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 350720,
     "status": "ok",
     "timestamp": 1551836066609,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "977XiQEf5hUX",
    "outputId": "9658bc01-9776-4f87-c022-809899b15d16"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'],label='train')\n",
    "  if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'],label='val')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.title('Loss during Training')\n",
    "  plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gEIj2vesfkV2"
   },
   "source": [
    "## Text Prediction\n",
    "\n",
    "Here we demonstrate the predictive nature of our model. In order to make a prediction, our model must be provided a seed. The seed must be equal to N (defined above as the input size to our model). In the example shown below, we seed our model with the first phrase of the book \"This tale grew in the\" and we expect each prediction to be the next word in the phrase, such as \"tale grew in the telling.\" The correct pairings are as follows:\n",
    "\n",
    "This => tale\n",
    "\n",
    "tale => grew\n",
    "\n",
    "grew => in\n",
    "\n",
    "in => the\n",
    "\n",
    "the => telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1551836079609,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "7V2LweZcjqfG",
    "outputId": "34fdb3f4-e131-4fa6-e38b-2ff85b028da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". => [('even', 0.6081218719482422)]\n",
      ". => [('less', 0.9473986029624939)]\n",
      ". => [('laborious', 0.9368656277656555)]\n",
      ". => [('.', 0.9998227953910828)]\n",
      ". => [('Then', 0.9802303314208984)]\n",
      ". => [('when', 0.9919359087944031)]\n",
      ". => [('the', 0.9987373948097229)]\n",
      ". => [(\"'end\", 0.977790117263794)]\n",
      ". => [(\"'\", 0.9978280067443848)]\n",
      ". => [('had', 0.9991677403450012)]\n",
      ". => [('at', 0.9994751214981079)]\n",
      ". => [('last', 0.989144504070282)]\n",
      ". => [('been', 0.9959170818328857)]\n",
      ". => [('reached', 0.9868970513343811)]\n",
      ". => [('the', 0.9996724128723145)]\n",
      ". => [('whole', 0.9800723791122437)]\n",
      ". => [('story', 0.9950727224349976)]\n",
      ". => [('had', 0.9991046190261841)]\n",
      ". => [('to', 0.9996762275695801)]\n",
      ". => [('be', 0.9962579011917114)]\n"
     ]
    }
   ],
   "source": [
    "def getTestingPhrase(sentence: str):\n",
    "    '''Converts a phrase with N tokens into a list of vectors'''\n",
    "    if len(sentence.split()) != N:\n",
    "        print(\"Sentence must contain exactly \" + str(N) + \" words.\")\n",
    "        return None\n",
    "    return np.array([my_embeddings[i] for i in sentence.split()])\n",
    "\n",
    "\n",
    "def printPredictions(predictions, testingPhrase):\n",
    "    '''Runs the vectorized phrase on the model and compares the predicted output to the ground truth'''\n",
    "    num_outputs = predictions.shape[1]\n",
    "    for i in range(num_outputs):\n",
    "        print(testingPhrase.split()[i] + \" => \", end='')\n",
    "        print(my_embeddings.most_similar(positive=[predictions[0][i]], topn=1))\n",
    "\n",
    "\n",
    "def predictNext(testingPhrase: str):\n",
    "    test_input = getTestingPhrase(testingPhrase)\n",
    "    test_input = np.expand_dims(test_input, axis=0)\n",
    "    predictions = model.predict(test_input)\n",
    "    printPredictions(predictions, testingPhrase)\n",
    "\n",
    "\n",
    "input_seed = train_input[0]\n",
    "# train_predict\n",
    "# validation_input\n",
    "# validation_predict\n",
    "\n",
    "input_seed = np.expand_dims(input_seed, axis=0)\n",
    "input_seed.shape\n",
    "predictions = model.predict(input_seed)\n",
    "printPredictions(predictions, \". . . . . . . . . . . . . . . . . . . .\")\n",
    "\n",
    "    \n",
    "# Use the first sentence of the text to test how well the model can recall the next word from the text\n",
    "    \n",
    "# This tale grew in the telling until it became a history of the Great War of the Ring \n",
    "# and included many glimpses of the yet more ancient history that preceded it.\n",
    "# predictNext(\"This tale grew in the\")\n",
    "# predictNext(\"telling until it became a\")\n",
    "# predictNext(\"history of the Great War\")\n",
    "# predictNext(\"of the Ring and included\")\n",
    "# predictNext(\"many glimpses of the yet\")\n",
    "# predictNext(\"more ancient history that preceded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that our model has done a good job memorizing sequences of text from the book. Our model starts off with lower accuracy because it is not provided with much context. But as the model predict subsequent terms, the accuracy increases. In this example, the model recalls 90% of the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -0.5]: {'lands', 'forest', 'About', 'woodlands', 'A', 'Of', 'land', 'To', 'has', 'An', ',', 'to', 'a', 'of'}\n",
      "[-0.5, 0]: {'forest', 'About', 'woodlands', 'Of', 'land', 'histories', ',', 'books', 'lands', 'records', 'of'}\n",
      "[0, 0.5]: {'A', 'where', 'for', 'The', 'but', 'But', 'That', 'the', 'before', 'in', 'In', 'that', 'a'}\n",
      "[0, 1]: {'It', 'A', 'could', 'where', 'The', 'but', 'not', 'the', 'in', 'that', 'it', 'a'}\n"
     ]
    }
   ],
   "source": [
    "def getSamplesFromRange(low, high):\n",
    "    print(\"[\"+str(low)+\",\"+\" \"+str(high)+\"]: \", end=\"\")\n",
    "    arr = []\n",
    "    for _ in range(N):\n",
    "        arr.append(np.random.uniform(low,high,300))\n",
    "    arr = np.array([np.array(arr)])\n",
    "    predictions = model.predict(arr)\n",
    "    num_outputs = predictions.shape[1]\n",
    "    outputs = set()\n",
    "    nns = 3 # nearest neighbors\n",
    "    for i in range(num_outputs):\n",
    "        tuple_list = my_embeddings.most_similar(positive=[predictions[0][i]], topn=3)\n",
    "        tokens = [i[0] for i in tuple_list]\n",
    "        outputs = outputs | set(tokens)\n",
    "    print(outputs)\n",
    "\n",
    "getSamplesFromRange(-1, -0.5)\n",
    "getSamplesFromRange(-0.5, 0)\n",
    "getSamplesFromRange(0, 0.5)\n",
    "getSamplesFromRange(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we experiment with the model's latent space by making the model predict specified ranges of vectors. From our experiments, the model has appeared to have clustered the input vectors based on their usage. Embeddings with values between [-1, 0] correspond to tokens that are used less often. Some examples that were generated in this range include: \n",
    "\n",
    "tale, '.', woodlands, chapter, '(', forest, ',', Prologue, remember\n",
    "\n",
    "On the other hand, embeddings with values between [0, 1] correspond to tokens that are used more often, such as stop words. Some examples in this range include: \n",
    "\n",
    "in, so, even, the, where, then, but, move, in, so, that, do, have, they, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n",
      "but\n"
     ]
    }
   ],
   "source": [
    "# Example output when the model is ran with all zeros\n",
    "arr = []\n",
    "for _ in range(N):\n",
    "    arr.append(np.zeros(300))\n",
    "arr = np.array([np.array(arr)])\n",
    "predictions = model.predict(arr)\n",
    "num_outputs = predictions.shape[1]\n",
    "for i in range(num_outputs):\n",
    "    print(my_embeddings.most_similar(positive=[predictions[0][i]], topn=1)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yi1_wqi0fhT2"
   },
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we experiment with text generation. The goal of text generation is to provide the model with a seed phrase and have the model generate many values into the \"future.\" We use an iterative algorithm to predict each word. \n",
    "\n",
    "Given a window size of $N$, to predict a word $w_i$, we input $[w_{i-N}, w_{i-N+1}, w_{i-N+2}, ..., w_{i-1}]$\n",
    "\n",
    "Then, we slide our window on top of our newly generated term and repeat this generation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1215,
     "status": "ok",
     "timestamp": 1551836084962,
     "user": {
      "displayName": "Andy W",
      "photoUrl": "https://lh3.googleusercontent.com/-e2yB0x7o_ZY/AAAAAAAAAAI/AAAAAAAAJuw/nAsmHlehdlY/s64/photo.jpg",
      "userId": "17506489879312600830"
     },
     "user_tz": 480
    },
    "id": "ygf_m4qVfgGd",
    "outputId": "9a2d316e-449f-41b4-9852-9a1cae638a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tale grew in the telling, until it became a history of the Great War of the Ring and included many glimpses other have have have but but but but but\n"
     ]
    }
   ],
   "source": [
    "# generate text out of input sequence string.\n",
    "# The seed input string has to contain at least N words.\n",
    "# If it contains more than N words only the last N will be feed into the network\n",
    "\n",
    "# get array of the last 5 words of the sentence\n",
    "def getVariableTestingPhrase(sentence: str):\n",
    "    '''Converts a variable length phrase with at least N tokens into a list of vectors'''\n",
    "    tokens = word_tokenize(sentence)\n",
    "    if len(tokens) < N:\n",
    "        print(\"Sentence must contain at least \" + str(N) + \" words.\")\n",
    "        return None\n",
    "    return np.array([my_embeddings[i] for i in tokens][-N:])\n",
    "\n",
    "\n",
    "def get_word_from_vector(array_seq):\n",
    "    '''Given the output to our model, obtain the last vector in the array\n",
    "    and fetch its corresponding text translation.'''\n",
    "    return my_embeddings.most_similar(positive=[array_seq[0][-1]], topn=1)[0]\n",
    "\n",
    "\n",
    "def generate_seq(model, seed_text, n_words):\n",
    "    '''Given the model and the seed text, the function will generate n_words number of tokens and\n",
    "    append these tokens to the end of the seed text'''\n",
    "    text_seq = seed_text.split()\n",
    "    # Input Data\n",
    "    text_array_seq = getVariableTestingPhrase(seed_text)\n",
    "    for i in range(n_words):\n",
    "        input = np.expand_dims(text_array_seq, axis=0)\n",
    "        pred = model.predict(input, verbose=0)\n",
    "        pred_word = get_word_from_vector(pred)\n",
    "        text_seq.append(pred_word[0])\n",
    "        # Append predicted word to the end of text_array_seq\n",
    "        # 1. Remove first\n",
    "        text_array_seq = text_array_seq[1:,:]\n",
    "        # 2. Append to last\n",
    "        last_pred = pred[:,-1,:]\n",
    "        text_array_seq = np.append(text_array_seq, last_pred, axis=0)\n",
    "    return ' ' .join(text_seq)\n",
    "  \n",
    "\n",
    "# \"This tale grew in the telling, until it became a history of the Great War of the Ring and included many\"\n",
    "seed_text = \"This tale grew in the telling, until it became a history of the Great War of the Ring and included many\"   \n",
    "generated_text = generate_seq(model, seed_text, 10)\n",
    "print(generated_text)\n",
    "\n",
    "\n",
    "# seed_text = \"Those who had asked for more information about\"\n",
    "# generated_text = generate_seq(model, seed_text, 10)\n",
    "# print(generated_text)\n",
    "\n",
    "# seed_text = \"Bilbo was very rich and\"\n",
    "# generated_text = generate_seq(model, seed_text, 10)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbRBtgaamGef"
   },
   "source": [
    "From the output above, our model does not do a good job of generating text beyond the next 3 words. The model exhibits signs of mode collapse because it repeats the same word over and over again. This may be because our model is focusing too much on the last term in the sequence in order to predict the next term. Once our model predicts a common word, it may expect a vector of similar value to come next. Since common words are clustered together (see above), the model gets stuck in a loop of only predicting common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Code",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
